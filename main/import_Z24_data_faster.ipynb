{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01C1403.aaa', '01C1405.aaa', '01C1406.aaa', '01C1407.aaa', '01C1410.aaa', '01C1412.aaa', '01C1414.aaa', '01C1416.aaa']\n",
      "['01C14POS.env', '01C14PRE.env']\n",
      "Channel data imported!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (20) does not match length of index (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Julian Gosliga\\Documents\\Python\\agnetwork\\main\\import_Z24_data_faster.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data_faster.ipynb#ch0000000?line=131'>132</a>\u001b[0m \u001b[39mfor\u001b[39;00m channel_name, units \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(channel_names, env_channel_units):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data_faster.ipynb#ch0000000?line=132'>133</a>\u001b[0m \tchannel_units_dict[channel_name] \u001b[39m=\u001b[39m units\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data_faster.ipynb#ch0000000?line=134'>135</a>\u001b[0m env_channels_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data\u001b[39m=\u001b[39;49menv_channel_values, index\u001b[39m=\u001b[39;49mreformatted_env_sample_timestamps)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data_faster.ipynb#ch0000000?line=136'>137</a>\u001b[0m all_channels_dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([acc_channels_dataframe, env_channels_dataframe], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data_faster.ipynb#ch0000000?line=137'>138</a>\u001b[0m all_channels_values \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39macc_channel_values, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39menv_channel_values}\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    637\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:125\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    122\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[0;32m    124\u001b[0m     \u001b[39m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     arrays \u001b[39m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[0;32m    126\u001b[0m     \u001b[39m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[39m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     \u001b[39m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:628\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    623\u001b[0m             val \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_multiget(val, oindex\u001b[39m.\u001b[39m_values, default\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan)\n\u001b[0;32m    625\u001b[0m         val \u001b[39m=\u001b[39m sanitize_array(\n\u001b[0;32m    626\u001b[0m             val, index, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, raise_cast_failure\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    627\u001b[0m         )\n\u001b[1;32m--> 628\u001b[0m         com\u001b[39m.\u001b[39;49mrequire_length_match(val, index)\n\u001b[0;32m    630\u001b[0m     homogenized\u001b[39m.\u001b[39mappend(val)\n\u001b[0;32m    632\u001b[0m \u001b[39mreturn\u001b[39;00m homogenized\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (20) does not match length of index (10)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import pymongo\n",
    "import decimal\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import this for timing only\n",
    "# import time\n",
    "\n",
    "def float_range(start, stop, step):\n",
    "\twhile start < stop:\n",
    "\t\tyield float(start)\n",
    "\t\tstart += decimal.Decimal(step)\n",
    "\n",
    "def generate_timestamps(time_offset, segment_start_date_time):\n",
    "\ttime_delta = datetime.timedelta(seconds = time_offset)\n",
    "\tsample_time = segment_start_date_time + time_delta\n",
    "\tsample_timestamp = datetime.datetime.timestamp(sample_time)\n",
    "\treturn int(sample_timestamp * timestamp_conversion_factor) \n",
    "\n",
    "# Saved Credentials\n",
    "credentials = {\n",
    "\t\"host\": \"localhost\",\n",
    "\t\"port\": \"27017\",\n",
    "\t\"username\": \"julian\",\n",
    "\t\"password\": \"CharcoalBaby1!\",\n",
    "\t\"authdb\": \"admin\",\n",
    "\t\"database\": \"drg-pbshm\",\n",
    "\t\"collection\": \"structures\"\n",
    "}\n",
    "\n",
    "timestamp_conversion_factor = 10**9\n",
    "export_directory = \"C:/Users/Julian Gosliga/Documents/json\"\n",
    "\n",
    "unit_conversions = {\"[V]\": \"V\", \"[°C]\": \"C\"}\n",
    "\n",
    "channel_types = {\"V\": \"voltage\", \"C\": \"temperature\", \"g\": \"acceleration\"}\n",
    "\n",
    "unique_env_channel_names = ['WS', 'WD', 'AT', 'R', 'H', 'TE', 'ADU', 'ADK', 'TSPU1', 'TSPU2', 'TSPU3', 'TSAU1', 'TSAU2', 'TSAU3', 'TSPK1', 'TSPK2', 'TSPK3', 'TSAK1', 'TSAK2', 'TSAK3', 'TBC1', 'TBC2', 'TSWS1', 'TSWN1', 'TWS1', 'TWC1', 'TWN1', 'TP1', 'TDT1', 'TDS1', 'TS1', 'TSWS2', 'TSWN2', 'TWS2', 'TWC2', 'TWN2', 'TP2', 'TDT2', 'TDS2', 'TS2', 'TWS3', 'TWN3', 'TWC3', 'TP3', 'TDT3', 'TS3']\n",
    "\n",
    "first_day = datetime.datetime(1997,11,10,14)\n",
    "day_offset = {\"A\": -2, \"B\": -1, \"C\": 0, \"D\": 1, \"E\": 2, \"F\": 3, \"G\": 4}\n",
    "\n",
    "main_dir = \"C:/Users/Julian Gosliga/Documents/Bridge Data/Z24_bridge_KUL/accelerations\"\n",
    "\n",
    "sub_dirs = [\"/Z24ems1\", \"/Z24ems2\", \"/Z24ems3\"]\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "\t# find data directories in first sub directory\n",
    "\tdata_dirs = next(os.walk(f\"{main_dir}{sub_dir}\"))[1]\n",
    "\n",
    "\tfor data_dir in data_dirs:\n",
    "\t\t# find the week, day, hour info for the data directory in question\n",
    "\t\tweek = data_dir[0:2]\n",
    "\t\tday = data_dir[2]\n",
    "\t\thour = data_dir[3:]\n",
    "\t\t# print(f\"week: {week}\\nday: {day}\\nhour: {hour}\")\n",
    "\t\t# calculate the day and time that the data was collected on\n",
    "\t\tdays_into_project = datetime.timedelta(hours = int(hour) - 14,days = day_offset[day], weeks = int(week) - 1)\n",
    "\t\tnew_date = first_day + days_into_project\n",
    "\t\t# print(new_date)\n",
    "\t\t# find data files within the first data directory in the first sub directory\n",
    "\t\tdata_files = next(os.walk(f\"{main_dir}{sub_dir}/{data_dir}\"))[2]\n",
    "\t\tchannel_units_dict = {}\n",
    "\t\t# find only the .aaa files and exclude the car log as its name is over 11 characters long\n",
    "\t\tacceleration_files = [file for file in data_files if file.endswith(\".aaa\") and len(file) == 11]\n",
    "\t\tprint(acceleration_files)\n",
    "\t\tacc_channel_values = {}\n",
    "\t\tfor j, acc_file in enumerate(acceleration_files):\n",
    "\t\t\twith open(f\"{main_dir}{sub_dir}/{data_dir}/{acc_file}\") as file:\n",
    "\t\t\t\tlines = file.readlines()\n",
    "\t\t\t\t# print(f\"current file: {main_dir}{sub_dir}/{data_dir}/{acc_file}\")\n",
    "\t\t\t\tchannel_number = acc_file[5:7]\n",
    "\t\t\t\tchannel_units_dict[channel_number] = \"g\"\n",
    "\t\t\t\tacc_channel_values[channel_number] = [float(line) for line in lines[3:65539]]\n",
    "\t\t\t\t# print(f\"channel number: {channel_number}\")\n",
    "\t\t\t\tsample_time_offsets = []\n",
    "\t\t\t\tsample_values = []\n",
    "\t\t\t\ttime_interval = float(lines[2])\n",
    "\t\t\t\tsegment_start_str = lines[65546].replace(\"Segment #1 Start :\",\"\").replace(\"\\n\", \"\")\n",
    "\t\t\t\tsegment_start_date_time = datetime.datetime.strptime(segment_start_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "\t\t\t\t# print(f\"Segment #1 Start :{segment_start_date_time}\")\n",
    "\t\t\tif j == 0:\n",
    "\t\t\t\t# assuming that all samples are taken at the same across the channels\n",
    "\t\t\t\tacc_sample_timestamps = [generate_timestamps(time_offset, segment_start_date_time) for time_offset in float_range(0, 65535 * time_interval, time_interval)]\n",
    "\t\t\t\t# print(acc_sample_timestamps)\n",
    "\n",
    "\t\tacc_channels_dataframe = pd.DataFrame(data=acc_channel_values, index=acc_sample_timestamps)\n",
    "\t\t# print(acc_channels_dataframe)\n",
    "\n",
    "\t\t# find the environmental files in the data directory\n",
    "\t\tenvironmental_files = [file for file in data_files if file.endswith(\"env\")]\n",
    "\t\tprint(environmental_files)\n",
    "\t\treformatted_env_sample_timestamps = []\n",
    "\t\tfor k, env_file in enumerate(environmental_files):\n",
    "\t\t\twith open(f\"{main_dir}{sub_dir}/{data_dir}/{env_file}\", encoding=\"iso-8859-1\") as file:\n",
    "\t\t\t\tfor i, line in enumerate(file):\n",
    "\t\t\t\t\tif i == 0:\n",
    "\t\t\t\t\t\tchannel_names = line.split()[::2]\n",
    "\t\t\t\t\t\tif k == 0:\n",
    "\t\t\t\t\t\t\tenv_channel_values = {c_n : [] for c_n in unique_env_channel_names}\n",
    "\t\t\t\t\t\t# print(f\"number of channels: {len(channel_names)}\")\n",
    "\t\t\t\t\t\t# print(f\"channel names from file: {channel_names}\")\n",
    "\t\t\t\t\t\tenv_channel_units = [unit_conversions[symbol] for symbol in line.split()[1::2]]\n",
    "\t\t\t\t\telif 11 > i >= 1:\n",
    "\t\t\t\t\t\traw_data = line.split()\n",
    "\t\t\t\t\t\t# print(f\"data line: {raw_data}\")\n",
    "\t\t\t\t\t\t# print(f\"entries in data line: {len(raw_data)}\")\n",
    "\t\t\t\t\t\tdel raw_data[45]\n",
    "\t\t\t\t\t\tdel raw_data[-6]\n",
    "\t\t\t\t\t\tfor j, (entry, channel_name) in enumerate(zip(raw_data, unique_env_channel_names)):\n",
    "\t\t\t\t\t\t\t# print(entry, channel_name)\n",
    "\t\t\t\t\t\t\tenv_channel_values[channel_name].append(float(entry))\n",
    "\t\t\t\t\telif line.startswith(\"EnvScan started : \"):\n",
    "\t\t\t\t\t\tsegment_start_str = line.replace(\"EnvScan started : \",\"\").replace(\"\\n\", \"\")\n",
    "\t\t\t\t\t\tsegment_start_date_time = datetime.datetime.strptime(segment_start_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "\t\t\t\t\telif line.startswith(\" Acquisition time :\"):\n",
    "\t\t\t\t\t\tsegment_duration_str = line.replace(\" Acquisition time :\", \"\").replace(\"number of scans : 10\", \"\")\n",
    "\t\t\t\t\t\tsegment_duration_timedelta = datetime.timedelta(seconds = float(segment_duration_str) / 10)\n",
    "\n",
    "\t\tenv_sample_times = [segment_start_date_time + segment_duration_timedelta * k for k in range(10)]\n",
    "\t\tenv_sample_timestamps = [datetime.datetime.timestamp(sample_time) for sample_time in env_sample_times]\n",
    "\t\treformatted_env_sample_timestamps = reformatted_env_sample_timestamps.copy() + [int(sample_timestamp * timestamp_conversion_factor) for sample_timestamp in env_sample_timestamps]\n",
    "\t\t# print(reformatted_env_sample_timestamps)\n",
    "\n",
    "\t\tprint(\"Channel data imported!\")\n",
    "\n",
    "\t\t# add units for environmental channels to global dict\n",
    "\t\tfor channel_name, units in zip(channel_names, env_channel_units):\n",
    "\t\t\tchannel_units_dict[channel_name] = units\n",
    "\n",
    "\t\tenv_channels_dataframe = pd.DataFrame(data=env_channel_values, index=reformatted_env_sample_timestamps)\n",
    "\n",
    "\t\tall_channels_dataframe = pd.concat([acc_channels_dataframe, env_channels_dataframe], axis=1)\n",
    "\t\tall_channels_values = {**acc_channel_values, **env_channel_values}\n",
    "\n",
    "\t\t# Connect to Server\n",
    "\t\tclient = pymongo.MongoClient(\"mongodb://{username}:{password}@{host}:{port}/{authdb}\".format(\n",
    "\t\tusername=urllib.parse.quote_plus(credentials[\"username\"]), password=urllib.parse.quote_plus(credentials[\"password\"]),\n",
    "\t\thost=credentials[\"host\"], port=credentials[\"port\"], authdb=credentials[\"authdb\"]\n",
    "\t\t), serverSelectionTimeoutMS = 2000)\n",
    "\t\t# call the server_info() to verify that client instance is valid\n",
    "\t\tclient.server_info() \n",
    "\n",
    "\t\tfor index, row in all_channels_dataframe.iterrows():\n",
    "\t\t\t# print(index)\n",
    "\t\t\tchannels = []\n",
    "\t\t\tfor channel_name in all_channels_values.keys():\n",
    "\t\t\t\tif not np.isnan(row[channel_name]):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tchannel_object = {\n",
    "\t\t\t\t\t\t\t\t\t\"name\": f\"channel-{channel_name}\",\n",
    "\t\t\t\t\t\t\t\t\t\"type\": channel_types[channel_units_dict[channel_name]],\n",
    "\t\t\t\t\t\t\t\t\t\"unit\": channel_units_dict[channel_name],\n",
    "\t\t\t\t\t\t\t\t\t\"value\": row[channel_name]\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\tchannels.append(channel_object)\n",
    "\n",
    "\t\t\toutput_json = {\n",
    "\t\t\t\t\t\t\"version\": \"1.1.0\",\n",
    "\t\t\t\t\t\t\"name\": \"z24-measurements\",\n",
    "\t\t\t\t\t\t\"population\": \"realbridges\",\n",
    "\t\t\t\t\t\t\"timestamp\": index,\n",
    "\t\t\t\t\t\t\"channels\": channels\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t\tjson = output_json\n",
    "\n",
    "\t\t\t# Insert JSON\n",
    "\t\t\tclient[credentials[\"database\"]][credentials[\"collection\"]].insert_one(json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1110b61dced1641dccdd8d71f876cc1ef9914396bc4fd3c4f6e92ba09b26db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
