{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import pymongo\n",
    "import decimal\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def float_range(start, stop, step):\n",
    "\twhile start < stop:\n",
    "\t\tyield float(start)\n",
    "\t\tstart += decimal.Decimal(step)\n",
    "\n",
    "def generate_timestamps(time_offset, segment_start_datetime):\n",
    "\ttime_delta = datetime.timedelta(seconds = time_offset)\n",
    "\tsample_time = segment_start_datetime + time_delta\n",
    "\tsample_timestamp = datetime.datetime.timestamp(sample_time)\n",
    "\treturn int(sample_timestamp * timestamp_conversion_factor) \n",
    "\n",
    "def index_channel_values_by_timestamp(timestamps, channel_values_dict):\n",
    "\tchannel_values_by_timestamp = {}\n",
    "\tfor i, timestamp in enumerate(timestamps):\n",
    "\t\ttimestamp_dict = {}\n",
    "\t\tfor channel in channel_values_dict.keys():\n",
    "\t\t\ttimestamp_dict[channel] = channel_values_dict[channel][i]\n",
    "\t\tchannel_values_by_timestamp[timestamp] = timestamp_dict\n",
    "\treturn channel_values_by_timestamp\n",
    "\n",
    "def check_datetime(datetime_to_check, correct_datetime, current_file):\n",
    "\tdate_match = True\n",
    "\thour_match = True\n",
    "\tif datetime_to_check.date() != correct_datetime.date():\n",
    "\t\tdate_match = False\n",
    "\tif datetime_to_check.hour != correct_datetime.hour:\n",
    "\t\thour_match = False\n",
    "\tif date_match and hour_match:\n",
    "\t\treturn datetime_to_check\n",
    "\telif date_match and not hour_match:\n",
    "\t\tprint(f\"\\nHours do not match in {current_file}\")\n",
    "\t\tnew_datetime = datetime_to_check.replace(hour = correct_datetime.hour)\n",
    "\telif not date_match and hour_match:\n",
    "\t\tprint(f\"\\nDates do not match in {current_file}\")\n",
    "\t\tnew_datetime = datetime_to_check.replace(year = correct_datetime.year, month = correct_datetime.month, day = correct_datetime.day)\n",
    "\telif not date_match and not hour_match:\n",
    "\t\tprint(f\"\\nDates and hours do not match in {current_file}\")\n",
    "\t\tnew_datetime = datetime_to_check.replace(year = correct_datetime.year, month = correct_datetime.month, day = correct_datetime.day, hour = correct_datetime.hour)\n",
    "\tprint(f\"Previous segment start time: {datetime_to_check}\")\n",
    "\tprint(f\"New segment start time: {new_datetime}\")\n",
    "\treturn new_datetime\n",
    "\n",
    "timestamp_conversion_factor = 10**9\n",
    "\n",
    "unit_conversions = {\"[V]\": \"V\", \"[°C]\": \"C\"}\n",
    "\n",
    "channel_types = {\"V\": \"voltage\", \"C\": \"temperature\", \"g\": \"acceleration\"}\n",
    "\n",
    "#  ADU is mislabelled as ADU in the emsdata.mat \n",
    "column_headings = ['AT', 'H', 'TE', 'ADU', 'TSPU1', 'TSPU2', 'TSAU1', 'TSAU2', 'TSAU3', 'TSPK1', 'TSPK2', 'TSAK1', 'TBC1', 'TBC2', 'TSWS1', 'TSWN1', 'TWS1', 'TWC1', 'TWN1', 'TP1', 'TDS1', 'TS1', 'TSWS2', 'TSWN2', 'TWC2', 'TWN2', 'TP2', 'TDT2', 'TDS2', 'TS2', 'TSWS3', 'TSWN3', 'TWS3', 'TWC3', 'TWN3', 'TDT3']\n",
    "\n",
    "env_column_mappings = {2: 'AT', 4: 'H', 5: 'TE', 6: 'ADU', 8: 'TSPU1', 9: 'TSPU2', 11: 'TSAU1', 12: 'TSAU2', 13: 'TSAU3', 14: 'TSPK1', 15: 'TSPK2', 17: 'TSAK1', 20: 'TBC1', 21: 'TBC2', 22: 'TSWS1', 23: 'TSWN1', 24: 'TWS1', 25: 'TWC1', 26: 'TWN1', 27: 'TP1', 29: 'TDS1', 30: 'TS1', 31: 'TSWS2', 32: 'TSWN2', 34: 'TWC2', 35: 'TWN2', 36: 'TP2', 37: 'TDT2', 38: 'TDS2', 39: 'TS2', 40: 'TSWS3', 41: 'TSWN3', 42: 'TWS3', 43: 'TWC3', 44: 'TWN3', 46: 'TDT3'}\n",
    "\n",
    "first_day = datetime.datetime(1997,11,10,14)\n",
    "day_offset = {\"A\": -2, \"B\": -1, \"C\": 0, \"D\": 1, \"E\": 2, \"F\": 3, \"G\": 4}\n",
    "\n",
    "total_number_of_data_dirs = 5653\n",
    "\n",
    "folder_count = 0\n",
    "\n",
    "average_time = 0\n",
    "n = 1\n",
    "\n",
    "# include option to time individual sections of the code\n",
    "timing = False\n",
    "\n",
    "current_folder = None\n",
    "\n",
    "current_sub_dir = None\n",
    "\n",
    "with open(\"./Z24-config.json\") as file:\n",
    "\tconfig = json.load(file)\n",
    "\tcredentials = config[\"credentials\"]\n",
    "\tmain_dir = config[\"mainDirectory\"]\n",
    "\texport_dir = config[\"exportDirectory\"]\n",
    "\n",
    "sub_dirs = [\"Z24ems1\", \"Z24ems2\", \"Z24ems3\"]\n",
    "\n",
    "if current_sub_dir != None:\n",
    "\tindex = sub_dirs.index(current_sub_dir)\n",
    "\tsub_dirs = sub_dirs[index:]\n",
    "for sub_dir in sub_dirs:\n",
    "\tif timing: start = time.time()\n",
    "\t# find data directories in first sub directory\n",
    "\tdata_dirs = next(os.walk(f\"{main_dir}/{sub_dir}\"))[1]\n",
    "\t# include option to start from a particular folder, e.g. if importing crashed partway through\n",
    "\tif current_folder != None:\n",
    "\t\tindex = data_dirs.index(current_folder)\n",
    "\t\tdata_dirs = data_dirs[index:]\n",
    "\t\tcurrent_folder = None\n",
    "\tif timing: print(f\"Data folders in current sub-driectory discovered in {round(time.time() - start, 5)} seconds\")\n",
    "\tfor data_dir in data_dirs:\n",
    "\t\tfolder_count += 1\n",
    "\t\toverall_start = time.time()\n",
    "\t\tif timing: \n",
    "\t\t\tstart = time.time()\n",
    "\t\t\tprint(f\"Currently importing: {data_dir}\")\n",
    "\t\telif current_folder != None or current_sub_dir != None:\n",
    "\t\t\tprint(f\"Currently importing: {sub_dir}/{data_dir} - Average time to import: {round(average_time, 5)} seconds\", end=\"\\r\")\n",
    "\t\telse:\n",
    "\t\t\tlength = 20\n",
    "\t\t\tpercent = 100 * (folder_count / float(total_number_of_data_dirs))\n",
    "\t\t\tfilled_length = int(length * folder_count // total_number_of_data_dirs)\n",
    "\t\t\tbar = \"▮\" * filled_length + \"-\" * (length - filled_length)\n",
    "\t\t\tprint(f\"Currently importing: {sub_dir}/{data_dir} - Progress: |{bar}| {percent:.2f}% - Average time to import: {round(average_time, 5)} seconds\", end=\"\\r\")\n",
    "\t\t# find the week, day, hour info for the data directory in question\n",
    "\t\tweek = data_dir[0:2]\n",
    "\t\tday = data_dir[2]\n",
    "\t\thour = data_dir[3:]\n",
    "\t\t# print(f\"\\nweek: {week}\\nday: {day}\\nhour: {hour}\")\n",
    "\t\t# calculate the day and time that the data was collected on\n",
    "\t\tdays_into_project = datetime.timedelta(hours = int(hour) - 14,days = day_offset[day], weeks = int(week) - 1)\n",
    "\t\tdatetime_from_folder_name = first_day + days_into_project\n",
    "\t\t# print(f\"Date and hour from folder name: {datetime_from_folder_name}\")\n",
    "\t\t# find data files within the first data directory in the first sub directory\n",
    "\t\tdata_files = next(os.walk(f\"{main_dir}/{sub_dir}/{data_dir}\"))[2]\n",
    "\t\tchannel_units_dict = {}\n",
    "\t\t# find only the .aaa files and exclude the car log as its name is over 11 characters long\n",
    "\t\tacceleration_files = [file for file in data_files if file.endswith(\".aaa\") and len(file) == 11]\n",
    "\t\t# print(acceleration_files)\n",
    "\t\tacc_channel_values = {}\n",
    "\t\tfor j, acc_file in enumerate(acceleration_files):\n",
    "\t\t\twith open(f\"{main_dir}/{sub_dir}/{data_dir}/{acc_file}\") as file:\n",
    "\t\t\t\tlines = file.readlines()\n",
    "\t\t\t\t# print(f\"current file: {main_dir}{sub_dir}/{data_dir}/{acc_file}\")\n",
    "\t\t\t\tchannel_number = acc_file[5:7]\n",
    "\t\t\t\tchannel_units_dict[channel_number] = \"g\"\n",
    "\t\t\t\tacc_channel_values[channel_number] = [float(line) for line in lines[3:65539]]\n",
    "\t\t\t\t# print(f\"channel number: {channel_number}\")\n",
    "\t\t\t\tsample_time_offsets = []\n",
    "\t\t\t\tsample_values = []\n",
    "\t\t\t\ttime_interval = float(lines[2])\n",
    "\t\t\t\tsegment_start_str = lines[65546].replace(\"Segment #1 Start :\",\"\").replace(\"\\n\", \"\")\n",
    "\t\t\t\tsegment_start_datetime = check_datetime(datetime.datetime.strptime(segment_start_str, \"%a %b %d %H:%M:%S %Y\"), datetime_from_folder_name, acc_file)\n",
    "\t\t\t\t# print(f\"Segment #1 Start :{segment_start_datetime}\")\n",
    "\t\t\t\t\t\n",
    "\t\t\tif j == 0:\n",
    "\t\t\t\t# assuming that all samples are taken at the same across the channels\n",
    "\t\t\t\tacc_sample_timestamps = [generate_timestamps(time_offset, segment_start_datetime) for time_offset in float_range(0, 65535 * time_interval, time_interval)]\n",
    "\t\t\t\t# print(acc_sample_timestamps)\n",
    "\t\t\n",
    "\t\tacc_channel_values_by_timestamp = index_channel_values_by_timestamp(acc_sample_timestamps, acc_channel_values)\n",
    "\t\t# print(acc_channel_values_by_timestamp)\n",
    "\n",
    "\t\t# find the environmental files in the data directory\n",
    "\t\tenvironmental_files = [file for file in data_files if file.endswith(\"env\")]\n",
    "\t\t# print(environmental_files)\n",
    "\t\treformatted_env_sample_timestamps = []\n",
    "\t\tfor k, env_file in enumerate(environmental_files):\n",
    "\t\t\twith open(f\"{main_dir}/{sub_dir}/{data_dir}/{env_file}\", encoding=\"iso-8859-1\") as file:\n",
    "\t\t\t\tfor i, line in enumerate(file):\n",
    "\t\t\t\t\tif i == 0:\n",
    "\t\t\t\t\t\tchannel_names = line.split()[::2]\n",
    "\t\t\t\t\t\tif k == 0:\n",
    "\t\t\t\t\t\t\tenv_channel_values = {c_n : [] for c_n in column_headings}\n",
    "\t\t\t\t\t\t# print(f\"number of channels: {len(channel_names)}\")\n",
    "\t\t\t\t\t\t# print(f\"channel names from file: {channel_names}\")\n",
    "\t\t\t\t\t\tenv_channel_units = [unit_conversions[symbol] for symbol in line.split()[1::2]]\n",
    "\t\t\t\t\t\tfor j, entry in enumerate(env_channel_units):\n",
    "\t\t\t\t\t\t\tif j in env_column_mappings: channel_units_dict[env_column_mappings[j]] = entry\n",
    "\t\t\t\t\t\t# print(env_channel_units)\n",
    "\t\t\t\t\telif 11 > i >= 1:\n",
    "\t\t\t\t\t\traw_data = line.split()\n",
    "\t\t\t\t\t\t# print(f\"data line: {raw_data}\")\n",
    "\t\t\t\t\t\t# print(f\"entries in data line: {len(raw_data)}\")\n",
    "\t\t\t\t\t\tfor j, entry in enumerate(raw_data):\n",
    "\t\t\t\t\t\t\t# print(entry, channel_name)\n",
    "\t\t\t\t\t\t\tif j in env_column_mappings: env_channel_values[env_column_mappings[j]].append(float(entry))\n",
    "\t\t\t\t\telif line.startswith(\"EnvScan started : \"):\n",
    "\t\t\t\t\t\tenvscan_start_str = line.replace(\"EnvScan started : \",\"\").replace(\"\\n\", \"\")\n",
    "\t\t\t\t\t\tenvscan_start_datetime = check_datetime(datetime.datetime.strptime(envscan_start_str, \"%a %b %d %H:%M:%S %Y\"), datetime_from_folder_name, env_file)\n",
    "\t\t\t\t\telif line.startswith(\" Acquisition time :\"):\n",
    "\t\t\t\t\t\tenvscan_duration_str = line.replace(\" Acquisition time :\", \"\").replace(\"number of scans : 10\", \"\")\n",
    "\t\t\t\t\t\tenvscan_duration_timedelta = datetime.timedelta(seconds = float(envscan_duration_str) / 10)\n",
    "\n",
    "\t\t\tenv_sample_times = [envscan_start_datetime + envscan_duration_timedelta * k for k in range(10)]\n",
    "\t\t\tenv_sample_timestamps = [datetime.datetime.timestamp(sample_time) for sample_time in env_sample_times]\n",
    "\t\t\treformatted_env_sample_timestamps = reformatted_env_sample_timestamps.copy() + [int(sample_timestamp * timestamp_conversion_factor) for sample_timestamp in env_sample_timestamps]\n",
    "\t\t\t# print(reformatted_env_sample_timestamps)\n",
    "\n",
    "\t\tenv_channel_values_by_timestamp = index_channel_values_by_timestamp(reformatted_env_sample_timestamps, env_channel_values)\n",
    "\t\t# print(env_channel_values_by_timestamp)\n",
    "\n",
    "\t\tall_channel_values_by_timestamp = {**env_channel_values_by_timestamp, **acc_channel_values_by_timestamp}\n",
    "\t\t# print(len(all_channel_values_by_timestamp.keys()))\n",
    "\t\t# print(all_channel_values_by_timestamp)\n",
    "\n",
    "\t\tif timing: print(f\"Channel data read from directory in {round(time.time()-start, 5)} seconds.\")\n",
    "\n",
    "\t\tif timing: start = time.time()\n",
    "\n",
    "\t\tdocuments = []\n",
    "\t\tfor timestamp in all_channel_values_by_timestamp.keys():\n",
    "\t\t\t# print(index)\n",
    "\t\t\tchannels = []\n",
    "\t\t\t# print(all_channel_values_by_timestamp[timestamp])\n",
    "\t\t\tfor channel_name in all_channel_values_by_timestamp[timestamp].keys():\n",
    "\t\t\t\tchannel_object = {\n",
    "\t\t\t\t\t\t\t\t\"name\": f\"channel-{channel_name}\",\n",
    "\t\t\t\t\t\t\t\t\"type\": channel_types[channel_units_dict[channel_name]],\n",
    "\t\t\t\t\t\t\t\t\"unit\": channel_units_dict[channel_name],\n",
    "\t\t\t\t\t\t\t\t\"value\": all_channel_values_by_timestamp[timestamp][channel_name]\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\tchannels.append(channel_object)\n",
    "\n",
    "\t\t\toutput_json = {\n",
    "\t\t\t\t\t\t\"version\": \"1.1.0\",\n",
    "\t\t\t\t\t\t\"name\": \"z24-measurements\",\n",
    "\t\t\t\t\t\t\"population\": \"realbridges\",\n",
    "\t\t\t\t\t\t\"timestamp\": timestamp,\n",
    "\t\t\t\t\t\t\"channels\": channels\n",
    "\t\t\t\t\t}\n",
    "\n",
    "\t\t\tdocuments.append(output_json)\n",
    "\n",
    "\t\tif timing: print(f\"json documents generated in {round(time.time()-start, 5)} seconds.\")\n",
    "\n",
    "\t\tif timing: start = time.time()\n",
    "\n",
    "\t\t# connect to Server\n",
    "\t\tclient = pymongo.MongoClient(\"mongodb://{username}:{password}@{host}:{port}/{authdb}\".format(\n",
    "\t\t\t\tusername=urllib.parse.quote_plus(credentials[\"username\"]), password=urllib.parse.quote_plus(credentials[\"password\"]),\n",
    "\t\t\t\thost=credentials[\"host\"], port=credentials[\"port\"], authdb=credentials[\"authdb\"]\n",
    "\t\t\t\t), serverSelectionTimeoutMS = 2000)\n",
    "\t\t# Insert JSON\n",
    "\t\tclient[credentials[\"database\"]][credentials[\"collection\"]].insert_many(documents)\n",
    "\n",
    "\t\tif timing: print(f\"Data successfully imported in {round(time.time()-start, 5)} seconds\")\n",
    "\n",
    "\t\tif timing: print(f\"Data folder imported in {round(time.time()-overall_start, 5)} seconds\")\n",
    "\n",
    "\t\taverage_time = average_time*((n-1)/n) + (time.time() - overall_start)/n\n",
    "\t\tn += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1110b61dced1641dccdd8d71f876cc1ef9914396bc4fd3c4f6e92ba09b26db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
