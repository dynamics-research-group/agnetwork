{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01C1403.aaa', '01C1405.aaa', '01C1406.aaa', '01C1407.aaa', '01C1410.aaa', '01C1412.aaa', '01C1414.aaa', '01C1416.aaa']\n",
      "['01C14POS.env', '01C14PRE.env']\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "BulkWriteError",
     "evalue": "batch op errors occurred, full error: {'writeErrors': [{'index': 0, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('62cecce4dce863c08d347627')}, 'errmsg': \"E11000 duplicate key error collection: drg-pbshm.structures index: _id_ dup key: { _id: ObjectId('62cecce4dce863c08d347627') }\", 'op': {'version': '1.1.0', 'name': 'z24-measurements', 'population': 'realbridges', 'timestamp': 879170513010000000, 'channels': [{'name': 'channel-03', 'type': 'acceleration', 'unit': 'g', 'value': -2.951459e-05}, {'name': 'channel-05', 'type': 'acceleration', 'unit': 'g', 'value': 8.816667e-05}, {'name': 'channel-06', 'type': 'acceleration', 'unit': 'g', 'value': 0.003213667}, {'name': 'channel-07', 'type': 'acceleration', 'unit': 'g', 'value': -3.815815e-05}, {'name': 'channel-10', 'type': 'acceleration', 'unit': 'g', 'value': -0.8022698}, {'name': 'channel-12', 'type': 'acceleration', 'unit': 'g', 'value': 0.001296}, {'name': 'channel-14', 'type': 'acceleration', 'unit': 'g', 'value': -0.0001326667}, {'name': 'channel-16', 'type': 'acceleration', 'unit': 'g', 'value': -0.000254}], '_id': ObjectId('62cecce4dce863c08d347627')}}], 'writeConcernErrors': [], 'nInserted': 0, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkWriteError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Julian Gosliga\\Documents\\Python\\agnetwork\\main\\import_Z24_data.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 129>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data.ipynb#ch0000000?line=159'>160</a>\u001b[0m client\u001b[39m.\u001b[39mserver_info() \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data.ipynb#ch0000000?line=160'>161</a>\u001b[0m \u001b[39m# Insert JSON\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Julian%20Gosliga/Documents/Python/agnetwork/main/import_Z24_data.ipynb#ch0000000?line=161'>162</a>\u001b[0m client[credentials[\u001b[39m\"\u001b[39;49m\u001b[39mdatabase\u001b[39;49m\u001b[39m\"\u001b[39;49m]][credentials[\u001b[39m\"\u001b[39;49m\u001b[39mcollection\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\u001b[39m.\u001b[39;49minsert_many(documents)\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\collection.py:691\u001b[0m, in \u001b[0;36mCollection.insert_many\u001b[1;34m(self, documents, ordered, bypass_document_validation, session, comment)\u001b[0m\n\u001b[0;32m    689\u001b[0m blk \u001b[39m=\u001b[39m _Bulk(\u001b[39mself\u001b[39m, ordered, bypass_document_validation, comment\u001b[39m=\u001b[39mcomment)\n\u001b[0;32m    690\u001b[0m blk\u001b[39m.\u001b[39mops \u001b[39m=\u001b[39m [doc \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m gen()]\n\u001b[1;32m--> 691\u001b[0m blk\u001b[39m.\u001b[39;49mexecute(write_concern, session\u001b[39m=\u001b[39;49msession)\n\u001b[0;32m    692\u001b[0m \u001b[39mreturn\u001b[39;00m InsertManyResult(inserted_ids, write_concern\u001b[39m.\u001b[39macknowledged)\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\bulk.py:512\u001b[0m, in \u001b[0;36m_Bulk.execute\u001b[1;34m(self, write_concern, session)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_no_results(sock_info, generator, write_concern)\n\u001b[0;32m    511\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_command(generator, write_concern, session)\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\bulk.py:393\u001b[0m, in \u001b[0;36m_Bulk.execute_command\u001b[1;34m(self, generator, write_concern, session)\u001b[0m\n\u001b[0;32m    390\u001b[0m     client\u001b[39m.\u001b[39m_retry_with_session(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_retryable, retryable_bulk, s, \u001b[39mself\u001b[39m)\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m full_result[\u001b[39m\"\u001b[39m\u001b[39mwriteErrors\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m full_result[\u001b[39m\"\u001b[39m\u001b[39mwriteConcernErrors\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 393\u001b[0m     _raise_bulk_write_error(full_result)\n\u001b[0;32m    394\u001b[0m \u001b[39mreturn\u001b[39;00m full_result\n",
      "File \u001b[1;32mc:\\Users\\Julian Gosliga\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\bulk.py:136\u001b[0m, in \u001b[0;36m_raise_bulk_write_error\u001b[1;34m(full_result)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mif\u001b[39;00m full_result[\u001b[39m\"\u001b[39m\u001b[39mwriteErrors\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    135\u001b[0m     full_result[\u001b[39m\"\u001b[39m\u001b[39mwriteErrors\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m error: error[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 136\u001b[0m \u001b[39mraise\u001b[39;00m BulkWriteError(full_result)\n",
      "\u001b[1;31mBulkWriteError\u001b[0m: batch op errors occurred, full error: {'writeErrors': [{'index': 0, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('62cecce4dce863c08d347627')}, 'errmsg': \"E11000 duplicate key error collection: drg-pbshm.structures index: _id_ dup key: { _id: ObjectId('62cecce4dce863c08d347627') }\", 'op': {'version': '1.1.0', 'name': 'z24-measurements', 'population': 'realbridges', 'timestamp': 879170513010000000, 'channels': [{'name': 'channel-03', 'type': 'acceleration', 'unit': 'g', 'value': -2.951459e-05}, {'name': 'channel-05', 'type': 'acceleration', 'unit': 'g', 'value': 8.816667e-05}, {'name': 'channel-06', 'type': 'acceleration', 'unit': 'g', 'value': 0.003213667}, {'name': 'channel-07', 'type': 'acceleration', 'unit': 'g', 'value': -3.815815e-05}, {'name': 'channel-10', 'type': 'acceleration', 'unit': 'g', 'value': -0.8022698}, {'name': 'channel-12', 'type': 'acceleration', 'unit': 'g', 'value': 0.001296}, {'name': 'channel-14', 'type': 'acceleration', 'unit': 'g', 'value': -0.0001326667}, {'name': 'channel-16', 'type': 'acceleration', 'unit': 'g', 'value': -0.000254}], '_id': ObjectId('62cecce4dce863c08d347627')}}], 'writeConcernErrors': [], 'nInserted': 0, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import pymongo\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "timestamp_conversion_factor = 10**9\n",
    "\n",
    "unit_conversions = {\"[V]\": \"V\", \"[Â°C]\": \"C\"}\n",
    "\n",
    "channel_types = {\"V\": \"voltage\", \"C\": \"temperature\", \"g\": \"acceleration\"}\n",
    "\n",
    "unique_env_channel_names = ['WS', 'WD', 'AT', 'R', 'H', 'TE', 'ADU', 'ADK', 'TSPU1', 'TSPU2', 'TSPU3', 'TSAU1', 'TSAU2', 'TSAU3', 'TSPK1', 'TSPK2', 'TSPK3', 'TSAK1', 'TSAK2', 'TSAK3', 'TBC1', 'TBC2', 'TSWS1', 'TSWN1', 'TWS1', 'TWC1', 'TWN1', 'TP1', 'TDT1', 'TDS1', 'TS1', 'TSWS2', 'TSWN2', 'TWS2', 'TWC2', 'TWN2', 'TP2', 'TDT2', 'TDS2', 'TS2', 'TWS3', 'TWN3', 'TWC3', 'TP3', 'TDT3', 'TS3']\n",
    "\n",
    "first_day = datetime.datetime(1997,11,10,14)\n",
    "day_offset = {\"A\": -2, \"B\": -1, \"C\": 0, \"D\": 1, \"E\": 2, \"F\": 3, \"G\": 4}\n",
    "\n",
    "with open(\"./Z24-config.json\") as file:\n",
    "\tconfig = json.load(file)\n",
    "\tcredentials = config[\"credentials\"]\n",
    "\tmain_dir = config[\"mainDirectory\"]\n",
    "\texport_dir = config[\"exportDirectory\"]\n",
    "\n",
    "sub_dirs = [\"/Z24ems1\", \"/Z24ems2\", \"/Z24ems3\"]\n",
    "\n",
    "# find data directories in first sub directory\n",
    "data_dirs = next(os.walk(f\"{main_dir}{sub_dirs[0]}\"))[1]\n",
    "\n",
    "# find the week, day, hour info for the data directory in question\n",
    "week = data_dirs[0][0:2]\n",
    "day = data_dirs[0][2]\n",
    "hour = data_dirs[0][3:]\n",
    "# print(f\"week: {week}\\nday: {day}\\nhour: {hour}\")\n",
    "# calculate the day and time that the data was collected on\n",
    "days_into_project = datetime.timedelta(hours = int(hour) - 14,days = day_offset[day], weeks = int(week) - 1)\n",
    "new_date = first_day + days_into_project\n",
    "# print(new_date)\n",
    "# find data files within the first data directory in the first sub directory\n",
    "data_files = next(os.walk(f\"{main_dir}{sub_dirs[0]}/{data_dirs[0]}\"))[2]\n",
    "channel_units_dict = {}\n",
    "# find only the .aaa files and exclude the car log as its name is over 11 characters long\n",
    "acceleration_files = [file for file in data_files if file.endswith(\".aaa\") and len(file) == 11]\n",
    "print(acceleration_files)\n",
    "acc_channel_values = {}\n",
    "for j, acc_file in enumerate(acceleration_files):\n",
    "\twith open(f\"{main_dir}{sub_dirs[0]}/{data_dirs[0]}/{acc_file}\") as file:\n",
    "\t\t# print(f\"current file: {main_dir}{sub_dirs[0]}/{data_dirs[0]}/{acc_file}\")\n",
    "\t\tchannel_number = acc_file[5:7]\n",
    "\t\tchannel_units_dict[channel_number] = \"g\"\n",
    "\t\tacc_channel_values[channel_number] = []\n",
    "\t\t# print(f\"channel number: {channel_number}\")\n",
    "\t\tsample_time_offsets = []\n",
    "\t\tsample_values = []\n",
    "\t\tfor i, line in enumerate(file):\n",
    "\t\t\t# temporarily changed from 65539 to 10 to make it easier to debug\n",
    "\t\t\tif 65539 > i >= 3:\n",
    "\t\t\t\tsample_number = i-2\n",
    "\t\t\t\tsample_time_offsets.append(datetime.timedelta(seconds = sample_number * time_interval))\n",
    "\t\t\t\tif channel_number in acc_channel_values:\n",
    "\t\t\t\t\tacc_channel_values[channel_number].append(float(line))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tacc_channel_values[channel_number] = [float(line)]\n",
    "\t\t\telif i == 2:\n",
    "\t\t\t\ttime_interval = float(line)\n",
    "\t\t\t\t# print(f\"time interval: {time_interval}\")\n",
    "\t\t\t# if i == 65538:\n",
    "\t\t\t\t# print(f\"final sample (number {sample_number}) is: {float(line)}\")\n",
    "\t\t\telif line.startswith(\"Segment #1 Start\"):\n",
    "\t\t\t\tsegment_start_str = line.replace(\"Segment #1 Start :\",\"\").replace(\"\\n\", \"\")\n",
    "\t\t\t\tsegment_start_date_time = datetime.datetime.strptime(segment_start_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "\t\t\t\t# print(f\"Segment #1 Start :{segment_start_date_time}\")\n",
    "\tif j == 0:\n",
    "\t\t# assuming that all samples are taken at the same across the channels\n",
    "\t\tacc_sample_times = [segment_start_date_time + time_offset for time_offset in sample_time_offsets]\n",
    "\t\tacc_sample_timestamps = [datetime.datetime.timestamp(sample_time) for sample_time in acc_sample_times]\n",
    "\t\treformatted_acc_sample_timestamps = [int(sample_timestamp * timestamp_conversion_factor) for sample_timestamp in acc_sample_timestamps]\n",
    "\t\t# print(reformatted_acc_sample_timestamps)\n",
    "\n",
    "acc_channels_dataframe = pd.DataFrame(data=acc_channel_values, index=reformatted_acc_sample_timestamps)\n",
    "# print(acc_channels_dataframe)\n",
    "\n",
    "# find the environmental files in the data directory\n",
    "environmental_files = [file for file in data_files if file.endswith(\"env\")]\n",
    "print(environmental_files)\n",
    "reformatted_env_sample_timestamps = []\n",
    "for k, env_file in enumerate(environmental_files):\n",
    "\twith open(f\"{main_dir}{sub_dirs[0]}/{data_dirs[0]}/{env_file}\", encoding=\"iso-8859-1\") as file:\n",
    "\t\tfor i, line in enumerate(file):\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tchannel_names = line.split()[::2]\n",
    "\t\t\t\tif k == 0:\n",
    "\t\t\t\t\tenv_channel_values = {c_n : [] for c_n in unique_env_channel_names}\n",
    "\t\t\t\t# print(f\"number of channels: {len(channel_names)}\")\n",
    "\t\t\t\t# print(f\"channel names from file: {channel_names}\")\n",
    "\t\t\t\tenv_channel_units = [unit_conversions[symbol] for symbol in line.split()[1::2]]\n",
    "\t\t\telif 11 > i >= 1:\n",
    "\t\t\t\traw_data = line.split()\n",
    "\t\t\t\t# print(f\"data line: {raw_data}\")\n",
    "\t\t\t\t# print(f\"entries in data line: {len(raw_data)}\")\n",
    "\t\t\t\tdel raw_data[45]\n",
    "\t\t\t\tdel raw_data[-6]\n",
    "\t\t\t\tfor j, (entry, channel_name) in enumerate(zip(raw_data, unique_env_channel_names)):\n",
    "\t\t\t\t\t# print(entry, channel_name)\n",
    "\t\t\t\t\tenv_channel_values[channel_name].append(float(entry))\n",
    "\t\t\telif line.startswith(\"EnvScan started : \"):\n",
    "\t\t\t\tsegment_start_str = line.replace(\"EnvScan started : \",\"\").replace(\"\\n\", \"\")\n",
    "\t\t\t\tsegment_start_date_time = datetime.datetime.strptime(segment_start_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "\t\t\telif line.startswith(\" Acquisition time :\"):\n",
    "\t\t\t\tsegment_duration_str = line.replace(\" Acquisition time :\", \"\").replace(\"number of scans : 10\", \"\")\n",
    "\t\t\t\tsegment_duration_timedelta = datetime.timedelta(seconds = float(segment_duration_str) / 10)\n",
    "\n",
    "\tenv_sample_times = [segment_start_date_time + segment_duration_timedelta * k for k in range(10)]\n",
    "\tenv_sample_timestamps = [datetime.datetime.timestamp(sample_time) for sample_time in env_sample_times]\n",
    "\treformatted_env_sample_timestamps = reformatted_env_sample_timestamps.copy() + [int(sample_timestamp * timestamp_conversion_factor) for sample_timestamp in env_sample_timestamps]\n",
    "\t# print(reformatted_env_sample_timestamps)\n",
    "\n",
    "# add units for environmental channels to global dict\n",
    "for channel_name, units in zip(channel_names, env_channel_units):\n",
    "\tchannel_units_dict[channel_name] = units\n",
    "\n",
    "env_channels_dataframe = pd.DataFrame(data=env_channel_values, index=reformatted_env_sample_timestamps)\n",
    "\n",
    "all_channels_dataframe = pd.concat([acc_channels_dataframe, env_channels_dataframe], axis=1)\n",
    "all_channels_values = {**acc_channel_values, **env_channel_values}\n",
    "\n",
    "documents = []\n",
    "for index, row in all_channels_dataframe.iterrows():\n",
    "\t# print(index)\n",
    "\tchannels = []\n",
    "\tfor channel_name in all_channels_values.keys():\n",
    "\t\tif not np.isnan(row[channel_name]):\n",
    "\t\t\t\n",
    "\t\t\tchannel_object = {\n",
    "\t\t\t\t\t\t\t\"name\": f\"channel-{channel_name}\",\n",
    "\t\t\t\t\t\t\t\"type\": channel_types[channel_units_dict[channel_name]],\n",
    "\t\t\t\t\t\t\t\"unit\": channel_units_dict[channel_name],\n",
    "\t\t\t\t\t\t\t\"value\": row[channel_name]\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\tchannels.append(channel_object)\n",
    "\n",
    "\toutput_json = {\n",
    "\t\t\t\t\"version\": \"1.1.0\",\n",
    "\t\t\t\t\"name\": \"z24-measurements\",\n",
    "\t\t\t\t\"population\": \"realbridges\",\n",
    "\t\t\t\t\"timestamp\": index,\n",
    "\t\t\t\t\"channels\": channels\n",
    "\t\t\t}\n",
    "\n",
    "\tdocuments.append(output_json)\n",
    "\t\n",
    "print(len(documents))\n",
    "\n",
    "# Connect to Server\n",
    "client = pymongo.MongoClient(\"mongodb://{username}:{password}@{host}:{port}/{authdb}\".format(\n",
    "\tusername=urllib.parse.quote_plus(credentials[\"username\"]), password=urllib.parse.quote_plus(credentials[\"password\"]),\n",
    "\thost=credentials[\"host\"], port=credentials[\"port\"], authdb=credentials[\"authdb\"]\n",
    "), serverSelectionTimeoutMS = 2000)\n",
    "# call the server_info() to verify that client instance is valid\n",
    "client.server_info() \n",
    "# Insert JSON\n",
    "client[credentials[\"database\"]][credentials[\"collection\"]].insert_many(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1110b61dced1641dccdd8d71f876cc1ef9914396bc4fd3c4f6e92ba09b26db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
